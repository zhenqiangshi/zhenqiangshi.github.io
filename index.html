<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Yes is Strong</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="We used to look up at the sky and wonder at our place in the stars, now we just look down and worry about our place in the dirt.">
<meta property="og:type" content="website">
<meta property="og:title" content="Yes is Strong">
<meta property="og:url" content="https://shizhenqiang.github.io/index.html">
<meta property="og:site_name" content="Yes is Strong">
<meta property="og:description" content="We used to look up at the sky and wonder at our place in the stars, now we just look down and worry about our place in the dirt.">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="JenKing">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Yes is Strong" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Yes is Strong</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">To let your hair down</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://shizhenqiang.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/20/hello-world/" class="article-date">
  <time class="dt-published" datetime="2022-06-20T08:22:54.000Z" itemprop="datePublished">2022-06-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/06/20/hello-world/">Quick Know</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <ul>
<li><p>石振强</p>
</li>
<li><p>男，92 生人</p>
</li>
<li><p>山东科技大学计算机本硕</p>
</li>
<li><p>机器学习、大数据、数据挖掘</p>
</li>
<li><p>python、java、shell</p>
</li>
<li><p>已婚，现居青岛</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shizhenqiang.github.io/2022/06/20/hello-world/" data-id="cl6nbi2wd000cczgpewk6fvmf" data-title="Quick Know" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Airflow" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/05/17/Airflow/" class="article-date">
  <time class="dt-published" datetime="2022-05-17T09:10:46.000Z" itemprop="datePublished">2022-05-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/05/17/Airflow/">Airflow</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一、-什么是airflow"><a href="#一、-什么是airflow" class="headerlink" title="一、 什么是airflow?"></a>一、 什么是airflow?</h2><p>它是一个具有（DAG）工作流调度器，并可视化其作业流程的一个平台。<a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/"><strong>Documentation&gt;&gt;</strong></a></p>
<blockquote>
<p><em>Airflow is a platform to programmatically author, schedule and monitor workflows.</em></p>
</blockquote>
<h2 id="二、什么是celery？"><a href="#二、什么是celery？" class="headerlink" title="二、什么是celery？"></a>二、什么是celery？</h2><p>它是一个简单、灵活且可靠的,处理大量消息的<strong>分布式</strong>系统,专注于实时处理的<strong>异步任务队列</strong>,同时也支持<strong>任务调度</strong>。 <a target="_blank" rel="noopener" href="https://docs.celeryq.dev/en/stable/"><strong>Documentation&gt;&gt;</strong></a></p>
<blockquote>
<p><em>Celery is a simple, flexible and reliable distributed system to process vast amounts of messages, while providing operations with the tools required to maintain such a system.</em></p>
</blockquote>
<h2 id="三、什么是Executor"><a href="#三、什么是Executor" class="headerlink" title="三、什么是Executor?"></a>三、什么是Executor?</h2><p>那些可以运行任务的执行者。例如：</p>
<p><strong>Local Executors</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/debug.html">Debug Executor</a></li>
<li><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/local.html">Local Executor</a></li>
<li><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/sequential.html">Sequential Executor</a></li>
</ul>
<p><strong>Remote Executors</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/celery.html">Celery Executor</a></li>
<li><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/celery_kubernetes.html">CeleryKubernetes Executor</a></li>
<li><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/dask.html">Dask Executor</a></li>
<li><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/kubernetes.html">Kubernetes Executor</a></li>
<li><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/local_kubernetes.html">LocalKubernetes Executor</a></li>
</ul>
<p>这里主要说明一下celery作为excutor的一个架构及流程。</p>
<img src="/2022/05/17/Airflow/graphviz-91fd3ca4f3dc01a69b3f84fbcd6b5c7975945ba4.png" class title="Architecture asset_img">

<ul>
<li><p><strong>Workers</strong> - Execute the assigned tasks</p>
</li>
<li><p><strong>Scheduler</strong> - Responsible for adding the necessary tasks to the queue</p>
</li>
<li><p><strong>Web server</strong> - HTTP Server provides access to DAG&#x2F;task status information</p>
</li>
<li><p><strong>Database</strong> - Contains information about the status of tasks, DAGs, Variables, connections, etc.</p>
</li>
<li><p><strong>Celery</strong> - Queue mechanism</p>
</li>
<li><p><strong>Broker</strong> - Stores commands for execution</p>
</li>
<li><p><strong>Result backend</strong> - Stores status of completed commands</p>
</li>
</ul>
<p>其中各个组件的联系如下：</p>
<ul>
<li>[1] <strong>Web server</strong> –&gt; <strong>Workers</strong> - Fetches task execution logs</li>
<li>[2] <strong>Web server</strong> –&gt; <strong>DAG files</strong> - Reveal the DAG structure</li>
<li>[3] <strong>Web server</strong> –&gt; <strong>Database</strong> - Fetch the status of the tasks</li>
<li>[4] <strong>Workers</strong> –&gt; <strong>DAG files</strong> - Reveal the DAG structure and execute the tasks</li>
<li>[5] <strong>Workers</strong> –&gt; <strong>Database</strong> - Gets and stores information about connection configuration, variables and XCOM.</li>
<li>[6] <strong>Workers</strong> –&gt; <strong>Celery’s result backend</strong> - Saves the status of tasks</li>
<li>[7] <strong>Workers</strong> –&gt; <strong>Celery’s broker</strong> - Stores commands for execution</li>
<li>[8] <strong>Scheduler</strong> –&gt; <strong>DAG files</strong> - Reveal the DAG structure and execute the tasks</li>
<li>[9] <strong>Scheduler</strong> –&gt; <strong>Database</strong> - Store a DAG run and related tasks</li>
<li>[10] <strong>Scheduler</strong> –&gt; <strong>Celery’s result backend</strong> - Gets information about the status of completed tasks</li>
<li>[11] <strong>Scheduler</strong> –&gt; <strong>Celery’s broker</strong> - Put the commands to be executed</li>
</ul>
<p>总结，webserver可视化DAG，获取任务状态，捕捉日志。Worker是执行任务的，同时存储相应的状态。scheduler是调度任务的，并将DAG存储下来。</p>
<p>如上，使用<a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/celery.html">Celery Executor</a>，得运行scheduler，worker。其中-D使用守护进程运行。当然你可以启动flower来监控<a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/stable/executor/celery.html">Celery Executor</a>的执行状况。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">airflow scheduler -D</span><br><span class="line">airflow celery worker -D</span><br><span class="line">airflow webserver -D</span><br><span class="line"></span><br><span class="line"># airflow celery flower #</span><br></pre></td></tr></table></figure>

<h2 id="四、什么是backfill？"><a href="#四、什么是backfill？" class="headerlink" title="四、什么是backfill？"></a>四、什么是backfill？</h2><p>可以在一定的时间范围内，运行一些DAG。</p>
<blockquote>
<p>Run subsections of a DAG for a specified date range.</p>
</blockquote>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">airflow dags backfill -s 2022-06-11 -e 2022-06-12 --reset-dagruns tutorial</span><br></pre></td></tr></table></figure>

<p>其中，reset_dag_run如果设置，那么他会提示是是否清除之前的DAG运行实例，重新运行。而rerun_failed_tasks则会自动执行在这个时间范围内的错误任务。</p>
<h2 id="五、有何依赖？"><a href="#五、有何依赖？" class="headerlink" title="五、有何依赖？"></a>五、有何依赖？</h2><p>airflow安装：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable constant_">AIRFLOW_VERSION</span>=<span class="number">2.3</span><span class="number">.2</span></span><br><span class="line"><span class="variable constant_">PYTHON_VERSION</span>=<span class="string">&quot;$(python --version | cut -d &quot;</span> <span class="string">&quot; -f 2 | cut -d &quot;</span>.<span class="string">&quot; -f 1-2)&quot;</span></span><br><span class="line"><span class="variable constant_">CONSTRAINT_URL</span>=<span class="string">&quot;https://raw.githubusercontent.com/apache/airflow/constraints-$&#123;AIRFLOW_VERSION&#125;/constraints-$&#123;PYTHON_VERSION&#125;.txt&quot;</span></span><br><span class="line">pip install <span class="string">&quot;apache-airflow[async,postgres,google]==$&#123;AIRFLOW_VERSION&#125;&quot;</span> --constraint <span class="string">&quot;$&#123;CONSTRAINT_URL&#125;&quot;</span></span><br></pre></td></tr></table></figure>

<p>你可以从文档中查看安装步骤，比如利用pypip安装，升级。<strong>注意版本</strong>。</p>
<p>mysql安装</p>
<p>如果用mysql作为元数据库，那么请注意版本以及配置编码等事宜。比如其中：</p>
<blockquote>
<p><em>In addition, you also should pay particular attention to MySQL’s encoding. Although the utf8mb4 character set is more and more popular for MySQL (actually, utf8mb4 becomes default character set in MySQL8.0), using the utf8mb4 encoding requires additional setting in Airflow 2+ (See more details in #7570.). If you use utf8mb4 as character set, you should also set sql_engine_collation_for_ids&#x3D;utf8mb3_bin.</em></p>
</blockquote>
<p>celery安装</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install &quot;apache-airflow[celery]==2.3.2&quot; --constraint &quot;https://raw.githubusercontent.com/apache/airflow/constraints-2.3.2/constraints-3.7.txt&quot;</span><br></pre></td></tr></table></figure>

<p>redis作为celery的backend时，还要安装redis，<strong>注意版本</strong>。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shizhenqiang.github.io/2022/05/17/Airflow/" data-id="cl6nbi2w60001czgpbuyi4kz0" data-title="Airflow" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Flink" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/07/18/Flink/" class="article-date">
  <time class="dt-published" datetime="2021-07-18T07:36:12.000Z" itemprop="datePublished">2021-07-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/07/18/Flink/">Flink 初探</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一、什么是Flink？"><a href="#一、什么是Flink？" class="headerlink" title="一、什么是Flink？"></a>一、什么是Flink？</h2><p>Apache Flink 是一个框架和分布式处理引擎，用于在无边界和有边界数据流上进行有状态的计算。Flink 能在所有常见集群环境中运行，并能以内存速度和任意规模进行计算。</p>
<blockquote>
<p><strong>Apache Flink</strong> is a framework and distributed processing engine for stateful computations over <em>unbounded</em> and <em>bounded</em> data streams. Flink has been designed to run in <em>all common cluster environments</em> perform computations at <em>in-memory</em> speed and at <em>any scale</em>.</p>
</blockquote>
<h2 id="二、-时间的概念"><a href="#二、-时间的概念" class="headerlink" title="二、 时间的概念"></a>二、 时间的概念</h2><p> <strong>Processing time:</strong> 执行各自操作的系统时间</p>
<p><strong>Event time:</strong> 各自事件的时间，发生在推送机器上的时间，在进入flink前的汇总信息的时间。使用时，必须指定如何生成<em>Event Time Watermarks</em>。</p>
<img src="/2021/07/18/Flink/event_processing_time.svg" class title="event processing time asset_img">

<h2 id="三、状态"><a href="#三、状态" class="headerlink" title="三、状态"></a>三、状态</h2><p>​      &#x2F;* TODO *&#x2F;</p>
<h2 id="四、窗口的类型"><a href="#四、窗口的类型" class="headerlink" title="四、窗口的类型"></a>四、窗口的类型</h2><ol>
<li><strong>Keyed Windows</strong></li>
<li><strong>Non-Keyed Windows</strong></li>
</ol>
<ul>
<li>滑动窗口</li>
<li>滚动窗口</li>
<li>全局窗口</li>
<li>会话窗口</li>
</ul>
<h2 id="五、定时器"><a href="#五、定时器" class="headerlink" title="五、定时器"></a>五、定时器</h2><p><a target="_blank" rel="noopener" href="https://github.com/apache/flink-training/blob/master/long-ride-alerts/README_zh.md">练习: <code>ProcessFunction</code> 及定时器（长车程警报）</a></p>
<p>尤其带状态的定时器一定要注意：</p>
<ol>
<li>状态什么时候clear？</li>
<li>定时器什么时候delete？</li>
</ol>
<h3 id="底线"><a href="#底线" class="headerlink" title="底线"></a>底线</h3><p>不管如何聪明地处理保持什么样的状态，以及选择保持多长时间，我们最终都应该清除它——否则状态将以无限的方式增长。 如果丢失了这些信息，我们将冒着延迟事件导致错误或重复结果的风险。</p>
<p>在永久地保持状态与在事件延迟时偶尔出错之间的权衡是有状态流处理中固有的挑战。</p>
<h3 id="如果你想走得更远"><a href="#如果你想走得更远" class="headerlink" title="如果你想走得更远"></a>如果你想走得更远</h3><p>对于下列的每一项，添加测试以检查所需的行为。</p>
<ul>
<li>扩展解决方案，使其永远不会泄漏状态。</li>
<li>定义事件丢失的含义，检测丢失的 START 和 END 事件，并将一些通知发送到旁路输出。</li>
</ul>
<h2 id="六、广播"><a href="#六、广播" class="headerlink" title="六、广播"></a>六、广播</h2><ul>
<li><p>if that is <strong>keyed</strong>, then the function is a <code>KeyedBroadcastProcessFunction</code>.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">KeyedBroadcastProcessFunction</span>&lt;KS, IN1, IN2, OUT&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">processElement</span><span class="params">(IN1 value, ReadOnlyContext ctx, Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">processBroadcastElement</span><span class="params">(IN2 value, Context ctx, Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onTimer</span><span class="params">(<span class="type">long</span> timestamp, OnTimerContext ctx, Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
<li><p>if it is <strong>non-keyed</strong>, the function is a <code>BroadcastProcessFunction</code>.</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">BroadcastProcessFunction</span>&lt;IN1, IN2, OUT&gt; <span class="keyword">extends</span> <span class="title class_">BaseBroadcastProcessFunction</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">processElement</span><span class="params">(IN1 value, ReadOnlyContext ctx, Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">processBroadcastElement</span><span class="params">(IN2 value, Context ctx, Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​    如上，都包含两个方法，分别是processElement()和 processBroadcastElement()，而这两个方法本身也有不同，非广播流方法（processElement）是一个 ReadOnlyContext而广播流（processBroadcastElement）方法是<strong>read-write access</strong>的，因为flink本身不具备cross-task通信，为了保证所有任务修改广播任务内容状态都会以同样的方式传到接下来每一个的输入元素，仅把broadcast设为可读可写。</p>
<p>​    除了以上说明还有几点重要的考虑：</p>
<ul>
<li><strong>There is no cross-task communication</strong> </li>
<li><strong>Order of events in Broadcast State may differ across tasks</strong> </li>
<li><strong>All tasks checkpoint their broadcast state</strong> </li>
<li><strong>No RocksDB state backend</strong></li>
</ul>
<h2 id="七、架构"><a href="#七、架构" class="headerlink" title="七、架构"></a>七、架构</h2><p>主要包含两种类型：</p>
<p>a <em>JobManager</em> and one or more <em>TaskManagers</em>.</p>
<img src="/2021/07/18/Flink/processes.svg" class title="processes asset_img">

<ol>
<li><h3 id="JobManager"><a href="#JobManager" class="headerlink" title="JobManager"></a>JobManager</h3></li>
<li><h3 id="TaskManagers"><a href="#TaskManagers" class="headerlink" title="TaskManagers"></a>TaskManagers</h3></li>
</ol>
<h2 id="八、Task-Slots-？"><a href="#八、Task-Slots-？" class="headerlink" title="八、Task Slots ？"></a>八、Task Slots ？</h2><p>TaskManager</p>
<p><strong>实践出真知</strong></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/ggHmSc86mN3I7r6snjqxWQ">https://mp.weixin.qq.com/s/ggHmSc86mN3I7r6snjqxWQ</a></li>
<li><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.12/concepts/flink-architecture.html">https://nightlies.apache.org/flink/flink-docs-release-1.12/concepts/flink-architecture.html</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/apache/flink-training/">https://github.com/apache/flink-training/</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shizhenqiang.github.io/2021/07/18/Flink/" data-id="cl6nbi2wa0004czgp2lbka194" data-title="Flink 初探" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Flink/" rel="tag">Flink</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-hbase" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/07/19/hbase/" class="article-date">
  <time class="dt-published" datetime="2019-07-19T03:02:56.000Z" itemprop="datePublished">2019-07-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/07/19/hbase/">hbase 初探</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>HBase基于LSM树模型实现，所有的数据写入操作首先会顺序写入日志HLog，再写入MemStore，当MemStore中数据大小超过阈值之后再将这些数据批量写入磁盘，生成一个新的HFile文件。LSM树架构有如下几个非常明显的优势：</p>
<ul>
<li>这种写入方式将一次随机IO写入转换成一个顺序IO写入（HLog顺序写入）加上一次内存写入（MemStore写入），使得<strong>写入性能</strong>得到极大提升。</li>
<li>HFile中KeyValue数据需要按照Key排序，排序之后可以在文件级别根据有序的Key建立索引树，极大提升数据<strong>读取性能</strong>。然而HDFS本身只允许顺序读写，不能更新，因此需要数据在落盘生成HFile之前就完成排序工作，<strong>MemStore就是KeyValue数据排序的实际执行者。</strong></li>
<li>MemStore作为一个缓存级的存储组件，总是缓存着最近写入的数据。</li>
<li>在数据写入HFile之前，可以在内存中对KeyValue数据进行很多更高级的优化。比如，MemStore在将数据写入HFile之前实际上可以丢弃老版本数据，仅保留最新版本数据。</li>
</ul>
<h2 id="RegionServer"><a href="#RegionServer" class="headerlink" title="RegionServer"></a>RegionServer</h2><img src="/2019/07/19/hbase/2022-08-10_11.08.43.png" class title="HBASE WRITE">

<p>一个RegionServer由一个（或多个）HLog、一个BlockCache以及多个Region组成。其中，HLog用来保证数据写入的可靠性；BlockCache可以将数据块缓存在内存中以提升数据读取性能；Region是HBase中数据表的一个数据分片，一个RegionServer上通常会负责多个Region的数据读写。一个Region由多个Store组成，每个Store存放对应列簇的数据，比如一个表中有两个列簇，这个表的所有Region就都会包含两个Store。每个Store包含一个MemStore和多个HFile，用户数据写入时会将对应列簇数据写入相应的MemStore，一旦写入数据的内存大小超过设定阈值，系统就会将MemStore中的数据落盘形成HFile文件。HFile存放在HDFS上，是一种定制化格式的数据存储文件，方便用户进行数据读取。</p>
<h2 id="一、写"><a href="#一、写" class="headerlink" title="一、写"></a>一、写</h2><img src="/2019/07/19/hbase/image-20220810110112338.png" class title="HBASE WRITE">

<ol>
<li>客户端处理阶段：客户端将用户的写入请求进行预处理，并根据集群<strong>元数据定位</strong>写入数据所在的RegionServer，将请求发送给对应的RegionServer。</li>
<li>Region写入阶段：RegionServer接收到写入请求之后将数据解析出来，首先写入WAL，再写入对应Region列簇的MemStore。</li>
<li>MemStore Flush阶段（异步flush，一个跳表满了之后，另一个跳表接收数据，之前的那个跳表异步flush）：当Region中MemStore容量超过一定阈值，系统会异步执行f lush操作，将内存中的数据写入文件，形成HFile。</li>
</ol>
<h3 id="BulkLoad是减少了哪一步？"><a href="#BulkLoad是减少了哪一步？" class="headerlink" title="BulkLoad是减少了哪一步？"></a>BulkLoad是减少了哪一步？</h3><p>BulkLoad首先使用MapReduce将待写入集群数据转换为HFile文件，再直接将这些HFile文件加载到在线集群中。显然，BulkLoad方案没有将写请求发送给RegionServer处理。</p>
<h2 id="二、读"><a href="#二、读" class="headerlink" title="二、读"></a>二、读</h2><p>HBase读数据的流程更加复杂，主要基于两个方面的原因：一是因为HBase一次范围查询可能会涉及多个Region、多块缓存甚至多个数据存储文件；二是因为HBase中更新操作以及删除操作的实现都很简单，更新操作并没有更新原有数据，而是使用时间戳属性实现了多版本；删除操作也并没有真正删除原有数据，只是插入了一条标记为”deleted”标签的数据，而真正的数据删除发生在系统异步执行Major Compact的时候。很显然，这种实现思路大大简化了数据更新、删除流程，但是对于数据读取来说却意味着套上了层层枷锁：读取过程需要根据版本进行过滤，对已经标记删除的数据也要进行过滤。</p>
<p>读流程从头到尾可以分为如下4个步骤：</p>
<p>Client-Server读取交互逻辑 &#x3D;&gt; Server端Scan框架体系 &#x3D;&gt; 过滤淘汰不符合查询条件的HFile &#x3D;&gt; 从HFile中读取待查找Key</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1、书名：HBase原理与实践作者：胡争，范欣欣出版社：机械工业出版社出版时间：2019-08ISBN：9787111634959</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shizhenqiang.github.io/2019/07/19/hbase/" data-id="cl6nbi2wc0009czgphoih3fua" data-title="hbase 初探" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hbase/" rel="tag">hbase</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-kafka" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/05/19/kafka/" class="article-date">
  <time class="dt-published" datetime="2019-05-19T03:02:36.000Z" itemprop="datePublished">2019-05-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/05/19/kafka/">kafka 问题汇总</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="一、为什么用MQ？"><a href="#一、为什么用MQ？" class="headerlink" title="一、为什么用MQ？"></a>一、为什么用MQ？</h2><ul>
<li>业务场景</li>
<li>解耦、异步、削峰</li>
</ul>
<h2 id="二、leader？"><a href="#二、leader？" class="headerlink" title="二、leader？"></a>二、leader？</h2><p>kafka集群的leader</p>
<p>每一个分区都有一个leader，leader负责读写，</p>
<h2 id="三、重复数据？"><a href="#三、重复数据？" class="headerlink" title="三、重复数据？"></a>三、重复数据？</h2><p>offset会定期自动提交给kafkabroker，告诉kafka我已经消费了，但是有可能重启或者kill掉后，offset来不及提交，导致下次消费的时候会重复消费未提交offset的数据。</p>
<p>具体如何去重，还要根据业务场景具体分析。</p>
<h2 id="四、数据丢失？"><a href="#四、数据丢失？" class="headerlink" title="四、数据丢失？"></a>四、数据丢失？</h2><p>防止丢数的设置：</p>
<p>生产者如果设置acks&#x3D;all 并且设置重试次数，就不会丢失。</p>
<p>消费者要设置副本，防止leader宕机后还有一个follower。</p>
<h2 id="五、消息顺序？"><a href="#五、消息顺序？" class="headerlink" title="五、消息顺序？"></a>五、消息顺序？</h2><p>如果按照key去划分固定一个partition的话，是顺序性的。否则如果划分到多个个partition就不会具有顺序性。</p>
<p>消费者如果多线程处理，也有可能让消息顺序混乱。那么一个方案就是建立多个内存队列，按照key去固定的划分到内存队列面，然后一个线程处理一个内存队列。增加处理速度。</p>
<p>参考</p>
<p>1、<a target="_blank" rel="noopener" href="https://github.com/doocs/advanced-java?utm_source=gold_browser_extension">https://github.com/doocs/advanced-java?utm_source=gold_browser_extension</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shizhenqiang.github.io/2019/05/19/kafka/" data-id="cl6nbi2we000eczgp0q2b38s9" data-title="kafka 问题汇总" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MQ/" rel="tag">MQ</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-About-hadoop" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2018/07/16/About-hadoop/" class="article-date">
  <time class="dt-published" datetime="2018-07-16T09:06:57.000Z" itemprop="datePublished">2018-07-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2018/07/16/About-hadoop/">hadoop 浅谈</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="hadoop浅谈"><a href="#hadoop浅谈" class="headerlink" title="hadoop浅谈"></a>hadoop浅谈</h1><h2 id="一、什么是hadoop"><a href="#一、什么是hadoop" class="headerlink" title="一、什么是hadoop"></a><strong>一、什么是hadoop</strong></h2><p>​    hadoop是一个开源的分布式计算和存储的框架。</p>
<h2 id="二、什么是mapreduce？"><a href="#二、什么是mapreduce？" class="headerlink" title="二、什么是mapreduce？"></a><strong>二、什么是mapreduce？</strong></h2><p>​    从总体上来讲，MapReduce主要包括三个阶段，map阶段， shuffle阶段， reduce阶段，如果大家对我前面讲的HDFS还有印象，应该能知道split这个过程，其实是HDFS帮我们做了，下面我从map的输入开始，剖析一下整个MapReduce的过程<img src="/2018/07/16/About-hadoop/529698-20180708160630717-1928465583.png" class title="MAPREDUCE asset_img"></p>
<p>   Map 函数拿到数据以后，会根据用户自定义的逻辑对数据进行处理，然后产生输出。</p>
<h2 id="三、什么是shuttle？"><a href="#三、什么是shuttle？" class="headerlink" title="三、什么是shuttle？"></a><strong>三、什么是shuttle？</strong></h2><p>​    <strong>Shuffle：MapReduce的“心脏”，是奇迹发生的地方。</strong> </p>
<img src="/2018/07/16/About-hadoop/529698-20180708163222772-1584131492.png" class title="shuttle asset_img">     

<p>在整个MapReduce的生命周期中，纯粹的Map阶段和过程的reduce过程，其实只占了很小的一部分，整个MapReduce的核心其实是Shuffle过程，也被称为奇迹发生的地方。之前那张Word Count过程图对shuffle这个过程体现的并不是很明显，因为那张图主要是想让大家用Word Count这个实际的列子，对MapReduce整个过程能有一个感性的认识，真正的MapReduce过程，应该像这张图所展示的一样，从map task输出到reduce task输入的这段过程都是shuffle，用一句话概括一下Shuffle做了什么事情就是，把map输出端的结果有序的传递给reduce的输入端。 从上面这个图可以看出，整个shuffle阶段，横跨了Map过程与Reduce过程，所以shuffle阶段又可分为map阶段的shuffle， map-shuffle 和 reduce 阶段的shuffle， reduce-shuffle， 在map-shuffle阶段主要完成了spill这个过程，在reduce-shuffle阶段，主要完成了copy和sort这个过程。 下面我们来详细的看一下shuffle阶段是如何通过spill，copy，sort这个三个过程，把map输出端的结果有序的传递给reduce的输入端。 先来看map-shuffle 阶段的 spill 过程 Spill过程简单来说就是把Map任务输出的中间结果写到本地磁盘上。以后供Reduce调用，做为Reduce端的输入。 但是怎么把中间结果写到磁盘上就比较有讲究了，不是随随便便一写就完事儿了，因为写磁盘的过程中既要考虑到写入的性能，因为不能出一个结果就写一次磁盘，出一个结果就写一次磁盘，这样效率会很低，又要考虑到为后续传递给reduce做准备。因为在实际使用中，一般会不止一个Reduce，而一个Map的输出，最后通常会传递给多个Reduce，如果我们能事先对Map的输出进行分区（这里讲一下partition的概念），或者说的更通俗一点就是把将来要传递给同一个reduce数据都有序的放在一起，这样就可以大大提升接下来从Map输出端拷贝输出结果到Reduce输入端的效率， 纯粹的map和存粹的reduce都只是很小的一部分，在map产生输出的时候，其实就已经的进入到了MapReduce的核心阶段，整个shuffle阶段由spill过程，copy过程，sort过程组成。</p>
<h2 id="四、-什么是YARN？"><a href="#四、-什么是YARN？" class="headerlink" title="四、 什么是YARN？"></a><strong>四、 什么是YARN？</strong></h2><p>​    Yarn的定义是 Yet Another Resource Negotiator，另一种资源协调者。 因为在Hadoop刚出来的时候，那时候还没有Yarn，Hadoop的工作调度都是由JobTracker和TaskTracker来做的，但是JobTracker和TaskTracker在设计上存在缺陷，主要问题是，单点压力过大最多只能支持近4000台机器，而且容易造成单点故障问题，所以慢慢的被弃用了，后来就出现了Yarn，Yarn在设计上更具有一般性，实际上MapReduce只是Yarn上的一个应用而已，Yarn上不但能支撑MapReduce，还能支撑自打出生以来就火的不要不要的内存计算并行计算框架Saprk，流式计算框架Storm 等等 … Yarn 由五个独立的实体组成。</p>
<ul>
<li><p>​    <strong>Client：用来提交（ MapReduce ）Job；</strong></p>
</li>
<li><p>​    <strong>ResourcesManager：用来管理协调分配集群中的资源；</strong></p>
</li>
<li><p>​    <strong>NodeManager：用来启动和监控本地计算机资源单位Container的利用情况；</strong></p>
</li>
<li><p>​    <strong>Application Master：用来协调（ MapReduce ）Job下的Task的运行；</strong></p>
</li>
<li><p>​    <strong>HDFS：用来在其他实体之间共享作业文件。</strong></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shizhenqiang.github.io/2018/07/16/About-hadoop/" data-id="cl6nbi2w20000czgp6wfp8zez" data-title="hadoop 浅谈" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Random-Forests" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2018/03/20/Random-Forests/" class="article-date">
  <time class="dt-published" datetime="2018-03-20T07:44:26.000Z" itemprop="datePublished">2018-03-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2018/03/20/Random-Forests/">Random Forests</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>顾名思义，是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。</p>
<p>​     其实质是对决策树算法的一种改进，将多个决策树合并在一起，每棵树的建立依赖于一个独立抽取的样品，森林中的每棵树具有相同的分布，分类误差取决于每一棵树的分类能力和它们之间的相关性。特征选择采用随机的方法去分裂每一个节点，然后比较不同情况下产生的误差。能够检测到的内在估计误差、分类能力和相关性决定选择特征的数目。单棵树的分类能力可能很小，<em><strong>但在随机产生大量的决策树后，一个测试样品可以通过每一棵树的分类结果经统计后选择最可能的分类。</strong></em></p>
<p><em><strong>决策树：</strong></em></p>
<p>​    决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果。</p>
<p>   随机森林是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类，然后看看哪一类被选择最多，就预测这个样本为那一类。</p>
<p>​    在建立每一棵决策树的过程中，有两点需要注意采样与完全分裂。首先是两个随机采样的过程，random forest对输入的数据要进行<em><strong>行、列的采样</strong></em>。对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting。然后进行列采样，从M个feature中，选择m个（m &lt;&lt; M）。之后就是对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。一般很多的决策树算法都一个重要的步骤——剪枝，但是这里不这样干，由于之前的两个随机采样的过程保证了随机性，所以就算不剪枝，也不会出现over-fitting。</p>
<p><em><strong>注意点：</strong></em></p>
<p><strong>设有N个样本，每个样本有M个features，决策树们其实都是随机地接受n个样本（对行随机取样）的m个feature（对列进行随机取样），每颗决策树的m个feature相同。每颗决策树其实都是对特定的数据进行学习归纳出分类方法，而随机取样可以保证有重复样本被不同决策树分类，这样就可以对不同决策树的分类能力做个评价。</strong></p>
<p><em><strong>随机森林 的过程：</strong></em></p>
<p>随机森林中的每一棵分类树为二叉树，其生成遵循<em><strong>自顶向下的递归分裂原则</strong></em>，即从根节点开始依次对训练集进行划分；在二叉树中，根节点包含全部训练数据， 按照节点纯度最小原则，分裂为左节点和右节点，它们分别包含训练数据的一个子集，按照同样的规则节点继续分裂，直到满足分支停止规则而停止生长。若节点n上的分类数据全部来自于同一类别，则此节点的纯度I(n)&#x3D;0，</p>
<p>纯度度量方法是Gini准则，即假设P(Xj)是节点n上属于Xj 类样本个数占训练。</p>
<p>具体实现过程如下：</p>
<p>（1）原始训练集为N，应用bootstrap法<strong>有放回地随机抽取k个新的自助样本集</strong>，并由此构建k棵分类树，每次未被抽到的样本组成了k个袋外数据；</p>
<p>（2）设有mall个变量，则在每一棵树的每个节点处随机抽取mtry个变量(mtry n mall)，然后在mtry中选择一个最具有分类能力的变量，变量分类的阈值通过检查每一个分类点确定；</p>
<p>（3）每棵树最大限度地生长, 不做任何修剪；</p>
<p>（4）将生成的多棵分类树组成随机森林，用随机森林分类器对新的数据进行判别与分类，分类结果按树分类器的投票多少而定。</p>
<p><a target="_blank" rel="noopener" href="http://blog.csdn.net/u012102306/article/details/52228516">Random Forest (sklearn 参数详解)</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shizhenqiang.github.io/2018/03/20/Random-Forests/" data-id="cl6nbi2wc0008czgp1ad4h0n3" data-title="Random Forests" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Apriori" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2018/01/09/Apriori/" class="article-date">
  <time class="dt-published" datetime="2018-01-09T06:16:43.000Z" itemprop="datePublished">2018-01-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2018/01/09/Apriori/">Apriori</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>看了很多博客，关于关联规则的介绍想做一个详细的汇总</p>
<h1 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a><strong>一、概念</strong></h1><p>表1 某超市的交易数据库</p>
<table>
<thead>
<tr>
<th>交易号TID</th>
<th>顾客购买的商品</th>
<th>交易号TID</th>
<th>顾客购买的商品</th>
</tr>
</thead>
<tbody><tr>
<td>T1</td>
<td>bread, cream, milk, tea</td>
<td>T6</td>
<td>bread, tea</td>
</tr>
<tr>
<td>T2</td>
<td>bread, cream, milk</td>
<td>T7</td>
<td>beer, milk, tea</td>
</tr>
<tr>
<td>T3</td>
<td>cake, milk</td>
<td>T8</td>
<td>bread, tea</td>
</tr>
<tr>
<td>T4</td>
<td>milk, tea</td>
<td>T9</td>
<td>bread, cream, milk, tea</td>
</tr>
<tr>
<td>T5</td>
<td>bread, cake, milk</td>
<td>T10</td>
<td>bread, milk, tea</td>
</tr>
</tbody></table>
<p><strong>定义一</strong>：设I&#x3D;{i1,i2,…,im}，是m个不同的项目的集合，每个ik称为一个<strong>项目</strong>。项目的集合I称为<strong>项集</strong>。其元素的个数称为项集的长度，长度为k的项集称为k-项集。引例中每个商品就是一个项目，项集为I&#x3D;{bread, beer, cake,cream, milk, tea}，I的长度为6。</p>
<p><strong>定义二</strong>：每笔<strong>交易</strong>T是项集I的一个子集。对应每一个交易有一个唯一标识交易号，记作TID。交易全体构成了<strong>交易数据库</strong>D，|D|等于D中交易的个数。引例中包含10笔交易，因此|D|&#x3D;10。</p>
<p><strong>定义三</strong>：对于项集X，设定count(X⊆T)为交易集D中包含X的交易的数量，则项集X的<strong>支持度</strong>为：</p>
<p>support(X)&#x3D;count(X⊆T)&#x2F;|D|</p>
<p>引例中X&#x3D;{bread, milk}出现在T1，T2，T5，T9和T10中，所以支持度为0.5。</p>
<p><strong>定义四</strong>：<strong>最小支持度</strong>是项集的最小支持阀值，记为SUPmin，代表了用户关心的关联规则的最低重要性。<strong>支持度不小于SUPmin 的项集称为频繁集</strong>，长度为k的频繁集称为k-频繁集。如果设定SUPmin为0.3，引例中{bread, milk}的支持度是0.5，所以是2-频繁集。</p>
<p><strong>定义五</strong>：<strong>关联规则</strong>是一个蕴含式：</p>
<p>R：X⇒Y</p>
<p>其中X⊂I，Y⊂I，并且X∩Y&#x3D;⌀。表示项集X在某一交易中出现，则导致Y以某一概率也会出现。用户关心的关联规则，可以用两个标准来衡量：支持度和可信度。</p>
<p><strong>定义六</strong>：关联规则R的<strong>支持度</strong>是交易集同时包含X和Y的交易数与|D|之比。即：</p>
<p>support(X⇒Y)&#x3D;count(X⋃Y)&#x2F;|D|</p>
<p>支持度反映了X、Y同时出现的概率。关联规则的支持度等于频繁集的支持度。 </p>
<p><strong>定义七</strong>：对于关联规则R，<strong>可信度</strong>是指包含X和Y的交易数与包含X的交易数之比。即：</p>
<p>confidence(X⇒Y)&#x3D;support(X⇒Y)&#x2F;support(X)</p>
<p>可信度反映了如果交易中包含X，则交易包含Y的概率。一般来说，只有支持度和可信度较高的关联规则才是用户感兴趣的。</p>
<p><strong>定义八</strong>：设定关联规则的最小支持度和最小可信度为SUPmin和CONFmin。规则R的支持度和可信度均不小于SUPmin和CONFmin ，则称为<strong>强关联规则</strong>。关联规则挖掘的目的就是找出强关联规则，从而指导商家的决策。</p>
<p>这八个定义包含了关联规则相关的几个重要基本概念，关联规则挖掘主要有两个问题：</p>
<ol>
<li>找出交易数据库中所有大于或等于用户指定的最小支持度的频繁项集。</li>
<li>利用频繁项集生成所需要的关联规则，根据用户设定的最小可信度筛选出强关联规则。</li>
</ol>
<p>目前研究人员主要针对第一个问题进行研究，找出频繁集是比较困难的，而有了频繁集再生成强关联规则就相对容易了。</p>
<h1 id="二、理论基础"><a href="#二、理论基础" class="headerlink" title="二、理论基础"></a>二、理论基础</h1><p>首先来看一个频繁集的性质。</p>
<p>定理：<strong>如果项目集X是频繁集，那么它的非空子集都是频繁集</strong>。</p>
<p>根据定理，已知一个k-频繁集的项集X，X的所有k-1阶子集都肯定是频繁集，也就肯定可以找到两个k-1频繁集的项集，它们只有一项不同，且连接后等于X。这证明了通过连接k-1频繁集产生的k-候选集覆盖了k-频繁集。同时，如果k-候选集中的项集Y，包含有某个k-1阶子集不属于k-1频繁集，那么Y就不可能是频繁集，应该从候选集中裁剪掉。Apriori算法就是利用了频繁集的这个性质。</p>
<h1 id="三、算法步骤："><a href="#三、算法步骤：" class="headerlink" title="三、算法步骤："></a><strong>三、算法步骤：</strong></h1><p>首先是测试数据：</p>
<table>
<thead>
<tr>
<th>交易ID</th>
<th><strong>商品<strong><strong>ID</strong></strong>列表</strong></th>
</tr>
</thead>
<tbody><tr>
<td>T100</td>
<td>I1，I2，I5</td>
</tr>
<tr>
<td>T200</td>
<td>I2，I4</td>
</tr>
<tr>
<td>T300</td>
<td>I2，I3</td>
</tr>
<tr>
<td>T400</td>
<td>I1，I2，I4</td>
</tr>
<tr>
<td>T500</td>
<td>I1，I3</td>
</tr>
<tr>
<td>T600</td>
<td>I2，I3</td>
</tr>
<tr>
<td>T700</td>
<td>I1，I3</td>
</tr>
<tr>
<td>T800</td>
<td>I1，I2，I3，I5</td>
</tr>
<tr>
<td>T900</td>
<td>I1，I2，I3</td>
</tr>
</tbody></table>
<p>算法的步骤图：</p>
<img src="/2018/01/09/Apriori/529698-20180109140825019-1205577597.png" class title="apriori asset_img"> 

<p>可以看到，第三轮的候选集发生了明显的缩小，这是为什么呢？</p>
<p>请注意取候选集的两个条件：</p>
<p>1.两个K项集能够连接的两个条件是，它们有K-1项是相同的。所以，（I2，I4）和（I3，I5）这种是不能够进行连接的。缩小了候选集。</p>
<p>2.如果一个项集是频繁集，那么它不存在不是子集的频繁集。比如（I1，I2）和（I1，I4）得到（I1，I2，I4），而（I1，I2，I4）存在子集（I1，I4）不是频繁集。缩小了候选集。</p>
<p>第三轮得到的2个候选集，正好支持度等于最小支持度。所以，都算入频繁集。</p>
<p>这时再看第四轮的候选集与频繁集结果为空</p>
<p>可以看到，候选集和频繁集居然为空了！因为通过第三轮得到的频繁集自连接得到{I1，I2，I3，I5}，它拥有子集{I2,I3,I5}，而{I2,I3,I5}不是频繁集，不满足：频繁集的子集也是频繁集这一条件，所以被剪枝剪掉了。所以整个算法终止，取最后一次计算得到的频繁集作为最终的频繁集结果：</p>
<p>也就是：[‘I1,I2,I3’, ‘I1,I2,I5’]</p>
<p><strong>四、代码：</strong>                                   </p>
<p>编写Python代码实现Apriori算法。代码需要注意如下两点：</p>
<ul>
<li>由于Apriori算法假定项集中的项是按字典序排序的，而集合本身是无序的，所以我们在必要时需要进行set和list的转换；</li>
<li>由于要使用字典（support_data）记录项集的支持度，需要用项集作为key，而可变集合无法作为字典的key，因此在合适时机应将项集转为固定集合frozenset。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">local_data</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">    dt = pd.read_excel(file_path)</span><br><span class="line">    data = dt[<span class="string">&#x27;con&#x27;</span>]</span><br><span class="line">    locdata = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">        locdata.append(<span class="built_in">str</span>(i).split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">   <span class="comment"># print(locdata)  # change to [[1,2,3],[1,2,3]]</span></span><br><span class="line">    length = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> locdata:</span><br><span class="line">        length.append(<span class="built_in">len</span>(i))  <span class="comment"># 计算长度并存储</span></span><br><span class="line">   <span class="comment"># print(length)</span></span><br><span class="line">    ki = length[length.index(<span class="built_in">max</span>(length))]</span><br><span class="line">   <span class="comment"># print(length[length.index(max(length))])  # length.index(max(length)读取最大值的位置，然后再定位取出最大值</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> locdata,ki</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_C1</span>(<span class="params">data_set</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Create frequent candidate 1-itemset C1 by scaning data set.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data_set: A list of transactions. Each transaction contains several items.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        C1: A set which contains all frequent candidate 1-itemsets</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    C1 = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> data_set:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> t:</span><br><span class="line">            item_set = <span class="built_in">frozenset</span>([item])</span><br><span class="line">            C1.add(item_set)</span><br><span class="line">    <span class="keyword">return</span> C1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_apriori</span>(<span class="params">Ck_item, Lksub1</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Judge whether a frequent candidate k-itemset satisfy Apriori property.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        Ck_item: a frequent candidate k-itemset in Ck which contains all frequent</span></span><br><span class="line"><span class="string">                 candidate k-itemsets.</span></span><br><span class="line"><span class="string">        Lksub1: Lk-1, a set which contains all frequent candidate (k-1)-itemsets.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        True: satisfying Apriori property.</span></span><br><span class="line"><span class="string">        False: Not satisfying Apriori property.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> Ck_item:</span><br><span class="line">        sub_Ck = Ck_item - <span class="built_in">frozenset</span>([item])</span><br><span class="line">        <span class="keyword">if</span> sub_Ck <span class="keyword">not</span> <span class="keyword">in</span> Lksub1:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_Ck</span>(<span class="params">Lksub1, k</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Create Ck, a set which contains all all frequent candidate k-itemsets</span></span><br><span class="line"><span class="string">    by Lk-1&#x27;s own connection operation.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        Lksub1: Lk-1, a set which contains all frequent candidate (k-1)-itemsets.</span></span><br><span class="line"><span class="string">        k: the item number of a frequent itemset.</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        Ck: a set which contains all all frequent candidate k-itemsets.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    Ck = <span class="built_in">set</span>()</span><br><span class="line">    len_Lksub1 = <span class="built_in">len</span>(Lksub1)</span><br><span class="line">    list_Lksub1 = <span class="built_in">list</span>(Lksub1)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len_Lksub1):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, len_Lksub1):</span><br><span class="line">            l1 = <span class="built_in">list</span>(list_Lksub1[i])</span><br><span class="line">            l2 = <span class="built_in">list</span>(list_Lksub1[j])</span><br><span class="line">            l1.sort()</span><br><span class="line">            l2.sort()</span><br><span class="line">            <span class="keyword">if</span> l1[<span class="number">0</span>:k-<span class="number">2</span>] == l2[<span class="number">0</span>:k-<span class="number">2</span>]:</span><br><span class="line">                Ck_item = list_Lksub1[i] | list_Lksub1[j]</span><br><span class="line">                <span class="comment"># pruning</span></span><br><span class="line">                <span class="keyword">if</span> is_apriori(Ck_item, Lksub1):</span><br><span class="line">                    Ck.add(Ck_item)</span><br><span class="line">    <span class="keyword">return</span> Ck</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_Lk_by_Ck</span>(<span class="params">data_set, Ck, min_support, support_data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Generate Lk by executing a delete policy from Ck.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data_set: A list of transactions. Each transaction contains several items.</span></span><br><span class="line"><span class="string">        Ck: A set which contains all all frequent candidate k-itemsets.</span></span><br><span class="line"><span class="string">        min_support: The minimum support.</span></span><br><span class="line"><span class="string">        support_data: A dictionary. The key is frequent itemset and the value is support.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Lk: A set which contains all all frequent k-itemsets.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    Lk = <span class="built_in">set</span>()</span><br><span class="line">    item_count = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> data_set:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> Ck:</span><br><span class="line">            <span class="keyword">if</span> item.issubset(t):</span><br><span class="line">                <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> item_count:</span><br><span class="line">                    item_count[item] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    item_count[item] += <span class="number">1</span></span><br><span class="line">    t_num = <span class="built_in">float</span>(<span class="built_in">len</span>(data_set))</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> item_count:</span><br><span class="line">        <span class="keyword">if</span> (item_count[item] / t_num) &gt;= min_support:</span><br><span class="line">            Lk.add(item)</span><br><span class="line">            support_data[item] = item_count[item] / t_num</span><br><span class="line">    <span class="keyword">return</span> Lk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_L</span>(<span class="params">data_set, k, min_support</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Generate all frequent itemsets.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data_set: A list of transactions. Each transaction contains several items.</span></span><br><span class="line"><span class="string">        k: Maximum number of items for all frequent itemsets.</span></span><br><span class="line"><span class="string">        min_support: The minimum support.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        L: The list of Lk.</span></span><br><span class="line"><span class="string">        support_data: A dictionary. The key is frequent itemset and the value is support.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    support_data = &#123;&#125;</span><br><span class="line">    C1 = create_C1(data_set)</span><br><span class="line">    L1 = generate_Lk_by_Ck(data_set, C1, min_support, support_data)</span><br><span class="line">    Lksub1 = L1.copy()</span><br><span class="line">    L = []</span><br><span class="line">    L.append(Lksub1)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, k+<span class="number">1</span>):</span><br><span class="line">        Ci = create_Ck(Lksub1, i)</span><br><span class="line">        Li = generate_Lk_by_Ck(data_set, Ci, min_support, support_data)</span><br><span class="line">        Lksub1 = Li.copy()</span><br><span class="line">        L.append(Lksub1)</span><br><span class="line">    <span class="keyword">return</span> L, support_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_big_rules</span>(<span class="params">L, support_data, min_conf</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Generate big rules from frequent itemsets.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        L: The list of Lk.</span></span><br><span class="line"><span class="string">        support_data: A dictionary. The key is frequent itemset and the value is support.</span></span><br><span class="line"><span class="string">        min_conf: Minimal confidence.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        big_rule_list: A list which contains all big rules. Each big rule is represented</span></span><br><span class="line"><span class="string">                       as a 3-tuple.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    big_rule_list = []</span><br><span class="line">    sub_set_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(L)):</span><br><span class="line">        <span class="keyword">for</span> freq_set <span class="keyword">in</span> L[i]:</span><br><span class="line">            <span class="keyword">for</span> sub_set <span class="keyword">in</span> sub_set_list:</span><br><span class="line">                <span class="keyword">if</span> sub_set.issubset(freq_set):</span><br><span class="line">                    conf = support_data[freq_set] / support_data[freq_set - sub_set]</span><br><span class="line">                    big_rule = (freq_set - sub_set, sub_set, conf)</span><br><span class="line">                    <span class="keyword">if</span> conf &gt;= min_conf <span class="keyword">and</span> big_rule <span class="keyword">not</span> <span class="keyword">in</span> big_rule_list:</span><br><span class="line">                        <span class="comment"># print freq_set-sub_set, &quot; =&gt; &quot;, sub_set, &quot;conf: &quot;, conf</span></span><br><span class="line">                        big_rule_list.append(big_rule)</span><br><span class="line">            sub_set_list.append(freq_set)</span><br><span class="line">    <span class="keyword">return</span> big_rule_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Test</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    file_path = <span class="string">&quot;test_aa.xlsx&quot;</span></span><br><span class="line">  </span><br><span class="line">    data_set,k = local_data(file_path)</span><br><span class="line">    L, support_data = generate_L(data_set, k, min_support=<span class="number">0.2</span>)</span><br><span class="line">    big_rules_list = generate_big_rules(L, support_data, min_conf=<span class="number">0.4</span>)</span><br><span class="line">    <span class="built_in">print</span>(L)</span><br><span class="line">    <span class="keyword">for</span> Lk <span class="keyword">in</span> L:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(<span class="built_in">list</span>(Lk)) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;frequent &quot;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(<span class="built_in">list</span>(Lk)[<span class="number">0</span>])) + <span class="string">&quot;-itemsets\t\tsupport&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">50</span>)</span><br><span class="line">        <span class="keyword">for</span> freq_set <span class="keyword">in</span> Lk:</span><br><span class="line">            <span class="built_in">print</span>(freq_set, support_data[freq_set])</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Big Rules&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> big_rules_list:</span><br><span class="line">        <span class="built_in">print</span>(item[<span class="number">0</span>], <span class="string">&quot;=&gt;&quot;</span>, item[<span class="number">1</span>], <span class="string">&quot;conf: &quot;</span>, item[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>

<p> 文件格式：</p>
<p>test_aa.xlsx</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">name    con</span><br><span class="line">T1     2,3,5</span><br><span class="line">T2     1,2,4</span><br><span class="line">T3     3,5</span><br><span class="line">T5     2,3,4</span><br><span class="line">T6     2,3,5</span><br><span class="line">T7     1,2,4</span><br><span class="line">T8     3,5</span><br><span class="line">T9     2,3,4</span><br><span class="line">T10    1,2,3,4,5</span><br></pre></td></tr></table></figure>

<p><strong>参考相关博客：</strong> 　　　　　　　　　　　　　　　　　　　</p>
<p><a target="_blank" rel="noopener" href="http://blog.csdn.net/rongyongfeikai2/article/details/40457827">http://blog.csdn.net/rongyongfeikai2/article/details/40457827</a></p>
<p><a target="_blank" rel="noopener" href="http://blog.csdn.net/opennaive/article/details/7051460">http://blog.csdn.net/opennaive/article/details/7051460</a></p>
<p><a target="_blank" rel="noopener" href="http://blog.csdn.net/opennaive/article/details/7047823">http://blog.csdn.net/opennaive/article/details/7047823</a></p>
<p><a target="_blank" rel="noopener" href="http://blog.csdn.net/androidlushangderen/article/details/43059211">http://blog.csdn.net/androidlushangderen/article/details/43059211</a></p>
<p>代码参考</p>
<p><a target="_blank" rel="noopener" href="http://blog.csdn.net/qq_32126633/article/details/78351726">http://blog.csdn.net/qq_32126633/article/details/78351726</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shizhenqiang.github.io/2018/01/09/Apriori/" data-id="cl6nbi2w90003czgp3g4142le" data-title="Apriori" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-GBDT" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/07/10/GBDT/" class="article-date">
  <time class="dt-published" datetime="2017-07-10T08:22:54.000Z" itemprop="datePublished">2017-07-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2017/07/10/GBDT/">GBDT</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="http://blog.csdn.net/yangtrees/article/details/7506052">机器学习——Gradient Boost Decision Tree(&amp;Treelink)</a></p>
<p><a target="_blank" rel="noopener" href="http://wenku.baidu.com/link?url=dmoD5irL8vAV5NnBmoz69M4J_tm-EZg8yGIcfEkTp_ApblW52F6LEv9GdJzusCCaTafPX5HxDObAtwJH77NmxOSp106W-kHCffX8KwC_YG7">greedy_function_approximation_a_gradient_boosting_machine</a></p>
<p><a target="_blank" rel="noopener" href="http://www.jianshu.com/p/005a4e6ac775">简书上很好的一个关于GBDT的例子</a></p>
<h1 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h1><h2 id="一、Regression-Decision-Tree"><a href="#一、Regression-Decision-Tree" class="headerlink" title="一、Regression Decision Tree"></a>一、Regression Decision Tree</h2><p>​    回归树总体流程类似于分类树，区别在于，回归树的每一个节点都会得一个预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但<strong>衡量最好的标准不再是最大熵，而是最小化平方误差</strong>。也就是被预测出错的人数越多，错的越离谱，平方误差就越大，通过最小化平方误差能够找到最可靠的分枝依据。分枝直到每个叶子节点上人的年龄都唯一或者达到预设的终止条件(如叶子个数上限)，若最终叶子节点上人的年龄不唯一，则以该节点上所有人的<em><strong>平均</strong></em>年龄做为该叶子节点的预测年龄。</p>
<h2 id="二、Boosting-Decision-Tree"><a href="#二、Boosting-Decision-Tree" class="headerlink" title="二、Boosting Decision Tree"></a>二、Boosting Decision Tree</h2><p>​    提升树是迭代多颗回归树来共同决策。每一棵决策树学习的是之前所有树的结论和残差(采用平方误差损失函数时)，拟合得到一个当前的残差回归树。残差的意义：<strong>残差 &#x3D; 真实值 - 预测值</strong>；提升树，即整个迭代过程生成的回归树的累加。预测值等于所有树值的累加。</p>
<img src="/2017/07/10/GBDT/1241" class title="model complex asset_img">



<p>​                                                                                                           提升树算法</p>
<h2 id="三、Gradient-Boosting-Decision-Tree"><a href="#三、Gradient-Boosting-Decision-Tree" class="headerlink" title="三、Gradient Boosting Decision Tree"></a>三、Gradient Boosting Decision Tree</h2><p>提升树利用加法模型和前向分类算法实现学习的优化过程。当损失函数平方损失和指数损失函数时，每一步的优化很简单，如平方损失函数学习残差回归树。</p>
<p>但对于一般的损失函数，往往每一步优化没那么容易，如上图中的绝对值损失函数和Huber损失函数。针对这一问题，Freidman提出了梯度提升算法： 利用最速下降的近似方法，即利用损失函数的负梯度在当前模型的值，作为回归问题中提升树算法的残差的近似值，拟合一个回归树。</p>
<img src="/2017/07/10/GBDT/1240" class title="model complex asset_img">

<p>​    当模型越复杂时，拟合的程度就越高，模型的训练偏差就越小。但此时如果换一组数据可能模型的变化就会很大，即模型的方差很大。所以模型过于复杂的时候会导致过拟合。<br>  当模型越简单时，即使我们再换一组数据，最后得出的学习器和之前的学习器的差别就不那么大，模型的方差很小。还是因为模型简单，所以偏差会很大。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shizhenqiang.github.io/2017/07/10/GBDT/" data-id="cl6nbi2wa0005czgpgp6k3rrp" data-title="GBDT" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Flink/" rel="tag">Flink</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MQ/" rel="tag">MQ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hbase/" rel="tag">hbase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Flink/" style="font-size: 10px;">Flink</a> <a href="/tags/Hadoop/" style="font-size: 10px;">Hadoop</a> <a href="/tags/MQ/" style="font-size: 10px;">MQ</a> <a href="/tags/hbase/" style="font-size: 10px;">hbase</a> <a href="/tags/machine-learning/" style="font-size: 20px;">machine learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">June 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/06/20/hello-world/">Quick Know</a>
          </li>
        
          <li>
            <a href="/2022/05/17/Airflow/">Airflow</a>
          </li>
        
          <li>
            <a href="/2021/07/18/Flink/">Flink 初探</a>
          </li>
        
          <li>
            <a href="/2019/07/19/hbase/">hbase 初探</a>
          </li>
        
          <li>
            <a href="/2019/05/19/kafka/">kafka 问题汇总</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 JenKing<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>